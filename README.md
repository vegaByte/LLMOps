# LLMOps

## Introduction

Welcome to LLMOps: Building with Large Language Models! We're thrilled that you've decided to enroll in the course, and we can't wait to see what you build throughout your journey. Before we dive into the main course, however, we want to quickly set some expectations and share some information that will help you as you progress.

1. Course Structure
This course is comprised of 6 core modules, each spanning several units. Each unit will feature a video like the introduction video you've just watched, and starting in Module 2, some units will feature an exercise component. All exercises in this course come in the form of Jupyter Notebooks, which can be run in Google Colab. None of the assignments are gradedâ€”they are there solely for you to practice your skills. 

2. Tools
We will use several tools in this course, some of which will require you to register an account. The tools which require an account are:

- Comet ML. When you registered for this course, a Comet account was automatically created for you using the same credentials you registered for this course with. You can login to your Comet account here to confirm.
- OpenAI. Throughout the course, we will at times use APIs from OpenAI. As a result, you will need to register for an OpenAI account, if you do not already have one. You can do so here.
- SerpApi. In one module, you will need to programmatically generate search results. To do this, we use SerpApi. You can register for a free account here.
- Google Colab. The notebooks shared in this course can be run in any Jupyter environment, but the easiest option is to simply run them in Google Colab, where you will have access to free GPUs. Colab works with any existing Google account.
In addition, we will be using many free and open source tools which do not require an account. These include Huggingface's Datasets library, Langchain, and Chroma. If you enjoy working with them, we'd recommend heading over to their GitHub repositories and leaving a "star."

## Content

- [x] Introduction
- [x] Welcome

Module 1: Introduction to LLMOps

- [x] 1.0 Introduction
- [x] 1.1 Brief Introduction to LLMs and LLMOps
- [x] 1.2 Overview of LLMOps Lifecycle
- [ ] 1.3 LLMOps Landscape
- [ ] 1.4 LLMOps vs MLOps
- [ ] 1.5 Introduction to Comet ML

Module 2: Working with LLMs

- [ ] 2.0 Introduction
- [ ] 2.1 Training LLMs: Strategies and Challenges
- [ ] 2.2 Selecting Your LLM
- [ ] 2.3 Prompting Engineering with LLMs
- [ ] 2.4 Fine-tuning and Customizing LLMs
- [ ] 2.5 Evaluating LLMs

Module 3: LLMOps in Practice

- [ ] 3.0 Introduction
- [ ] 3.1 Debugging LLMs
- [ ] 3.2 Model Versioning and Management
- [ ] 3.3 Deployment of LLMs
- [ ] 3.4 Monitoring and Maintaining LLMs in Production

Module 4: Case Studies & Applications of LLMOps

- [ ] 4.0 Introduction
- [ ] 4.1 Overview of Use Cases & Applications
- [ ] 4.2 Case Study 1: Building a Reliable Customer Support Chatbot
- [ ] 4.3 Case Study 2: LLM-Powered Evaluation System
- [ ] 4.4 Hands-on Project: Clickbait Detector

Module 5: Advanced Topics in LLMs & LLMOps

- [ ] 5.0 Introduction
- [ ] 5.1 Scaling with LLMOps: Dealing with Larger Models and More Data
- [ ] 5.2 Privacy and Security in LLMOps
- [ ] 5.3 AI Safety
- [ ] 5.4 Adversarial Prompting

Module 6: The Future of LLMOps

- [ ] 6.0 Introduction
- [ ] 6.1 Emerging Trends in LLMOps
- [ ] 6.2 The Role of LLMOps in the Broader MLOps Landscape
- [ ] 6.3 Looking Ahead: The Roadmap for LLMOps
- [ ] 6.4 Final Words